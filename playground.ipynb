{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test methods, funtions and algorithms\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords, state_union\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3daaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello Mrs. Doe, hope everything is well. I am excited to learn Python. I am nervous about the project.\"\n",
    "stopwrds = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(text)\n",
    "filteredSent = []\n",
    "trainText = state_union.raw(\"2005-GWBush.txt\")\n",
    "samplText = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cusTok = PunktSentenceTokenizer(trainText)\n",
    "tokenz = cusTok.tokenize(samplText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb6a91",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tagFile():\n",
    "    try:\n",
    "        for i in tokenz:\n",
    "            words = word_tokenize(i)\n",
    "            tags = nltk.pos_tag(words)\n",
    "            print(tags)\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60215bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a499f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27faf48a",
   "metadata": {},
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b27b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97046aa1",
   "metadata": {},
   "source": [
    "for w in words:\n",
    "   if w not in stopwrds:\n",
    "       filteredSent.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1c09d",
   "metadata": {},
   "source": [
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299eefb",
   "metadata": {},
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269047cf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
